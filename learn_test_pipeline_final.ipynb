{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQs-lq2B67pX"
      },
      "outputs": [],
      "source": [
        "!pip install -U albumentations\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqMC50Kv6BeV"
      },
      "source": [
        "Для оубчения модели необхожимо в словаре train_config указать нужные параметры для обучения, а именно:\n",
        "* путь для валидационного и обучаещего датасета - train_data_path, valid_data_path соответсвенно.<br>\n",
        "* is_custom_model - является ли модель для обучения собственной архитектурой (True/False)\n",
        "* img_size - размер фотографии\n",
        "* num_epochs - количество эпох\n",
        "* batch_size - размер батчаей\n",
        "* lr - learning_rate для градиентного спуска\n",
        "\n",
        "В методе train_model класса Model_train можно указать нужную функцию потерь и тип градиентного спуска, заменив значения переменных <br>\n",
        "criterion = nn.CrossEntropyLoss()<br>\n",
        "optimizer = optim.Adam(self.model.parameters(), lr=self.train_config['lr'])<br>\n",
        "на нужные<br>\n",
        "\n",
        "в train_albumentations_transforms можно заменит параметры аугментации на нужные.\n",
        "Для запуск тестирования модели необходимо в словаре test_config указать нужные параметры. Описание параметров совпадает с параметрами для train_config.\n",
        "\n",
        "Более подробные описания методов представленна в коде в комментариях."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K0iOP37hmCuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqXdbM1r2e8Y",
        "outputId": "cceb939c-8485-4489-df5f-7a6873295ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.24 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import albumentations as A\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG-VM57WRyHP"
      },
      "source": [
        "# Классы для обучения, загрузки датасета и класс модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeW9Hyyl9vl2"
      },
      "outputs": [],
      "source": [
        "# Класс загрузчика данных. Принимает путь до датсета, размер фотографии и экземпляр\n",
        "# класса для аугментации\n",
        "class Data_loader:\n",
        "    def __init__(self, dataset_path, img_size, alb_transform=None):\n",
        "        self.dataset = ImageFolder(root=dataset_path)\n",
        "        self.img_size = img_size\n",
        "        self.alb_transform = alb_transform\n",
        "        self.to_tensor_transform = transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = self.dataset[idx]\n",
        "        img = img.convert(\"RGB\")\n",
        "\n",
        "        if self.alb_transform:\n",
        "            img = self.alb_transform(image=np.array(img))['image']\n",
        "            img = self.to_tensor_transform(img)\n",
        "\n",
        "            return img, target\n",
        "\n",
        "\n",
        "    def get_test_item(self, idx):\n",
        "        test_transform = transforms.Resize((self.img_size, self.img_size))\n",
        "        img = self.to_tensor_transform(img)\n",
        "        img, target = self.test_dataset[idx]\n",
        "        img = img.convert(\"RGB\")\n",
        "        img = test_transform(img)\n",
        "        img = self.to_tensor_transform(img)\n",
        "\n",
        "        return img, target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ND2aH-hMbvbX"
      },
      "outputs": [],
      "source": [
        "# Класс для обучения модели. При иннициализации принимает архитектуру модели, класс загрузчика для тренировочного и валидационного датасета\n",
        "# И словарь с параметрами обучения\n",
        "# При необходимоти тут можно поменять функцию потерь и метод градиентного спуска\n",
        "class Train_model:\n",
        "    def __init__(self, model, train_dataset, valid_dataset, train_config):\n",
        "        self.train_dataset = train_dataset\n",
        "        self.train_dataset = valid_dataset\n",
        "        self.train_config = train_config\n",
        "        self.model = model\n",
        "        self.train_loader = DataLoader(train_dataset, batch_size = self.train_config['batch_size'])\n",
        "        self.valid_loader = DataLoader(valid_dataset, batch_size = self.train_config['batch_size'])\n",
        "        self.is_custom_model = train_config['is_custom_model']\n",
        "\n",
        "        train_targets = []\n",
        "        for img, lbl in self.train_loader:\n",
        "            train_targets.append(lbl.numpy())\n",
        "\n",
        "        valid_targets = []\n",
        "        for img, lbl in self.valid_loader:\n",
        "            valid_targets.append(lbl.numpy())\n",
        "\n",
        "        self.train_targets = np.concatenate(train_targets)\n",
        "        self.valid_targets = np.concatenate(valid_targets)\n",
        "\n",
        "\n",
        "    def forward_dataset(self, dataloader):# Прогон всего датасета через модель\n",
        "        predict_list = []\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(dataloader, 0):\n",
        "                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "                outputs = self.model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                predict_list.append(predicted.tolist())\n",
        "\n",
        "\n",
        "        return np.concatenate(predict_list)\n",
        "\n",
        "\n",
        "    def train_model(self): # метод тренировки модели\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss() # Если класса всего два, то поставить бинарную кросс энтрапию\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=self.train_config['lr']) # поменять метод градиентного спуска, если нужно\n",
        "\n",
        "        if self.is_custom_model:\n",
        "            self.model.set_custom_weights()\n",
        "\n",
        "        for epoch in range(self.train_config['num_epochs']):\n",
        "            print(f\"epoch {epoch + 1} / {train_config['num_epochs']}\")\n",
        "\n",
        "            for i, data in enumerate(self.train_loader, 0):\n",
        "                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = self.model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            self.model.eval()\n",
        "\n",
        "            valid_predict = self.forward_dataset(self.valid_loader)\n",
        "            train_predict = self.forward_dataset(self.train_loader)\n",
        "\n",
        "            train_accurcay = round(accuracy_score(self.train_targets, train_predict), 3)\n",
        "            valid_accuracy = round(accuracy_score(self.valid_targets, valid_predict), 3)\n",
        "            valid_f1 = round(f1_score(self.valid_targets, valid_predict, average='macro'), 3)\n",
        "            valid_precision = round(precision_score(self.valid_targets, valid_predict, average='macro'), 3)\n",
        "            valid_recall = round(recall_score(self.valid_targets, valid_predict, average='macro'), 3)\n",
        "\n",
        "            self.model.train()\n",
        "\n",
        "            print(f'Train_loss: {loss.item()}, Train_accuracy: {train_accurcay}, Valid_accuracy: {valid_accuracy}, Valid_f1: {valid_f1}, valid_precision: {valid_precision}, valid_recall: {valid_recall}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veqzP59SHpWA"
      },
      "outputs": [],
      "source": [
        "class CustomCNN(nn.Module): # Настроить для себя архитектуру модели, если нужно\n",
        "    def __init__(self, num_classes):\n",
        "        super(CustomCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 56 * 56)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.softmax(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "    def set_custom_weights(self):\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.zeros_(self.fc1.bias)\n",
        "        nn.init.kaiming_uniform_(self.fc2.weight, a=nn.init.calculate_gain('relu'))\n",
        "        nn.init.zeros_(self.fc2.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcDxpwcvPRDP"
      },
      "source": [
        "# Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r308b_AzPbBB"
      },
      "source": [
        "## Настройка параметров обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DQDRvX02zB8"
      },
      "outputs": [],
      "source": [
        "# Выбрать нужные параметры для процесса обучения модели.\n",
        "train_config = {\n",
        "    'train_data_path': '/content/drive/MyDrive/hackathon/train',\n",
        "    'valid_data_path': '/content/drive/MyDrive/hackathon/valid',\n",
        "    'is_custom_model': False, # Если используется собственная архитектура CustomCNN, поменять на True\n",
        "    'img_size': 224,\n",
        "    'num_epochs': 15,\n",
        "    'batch_size': 50,\n",
        "    'lr': 0.0001 # learning_rate для градиентного спуска\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqgJFrkbPT_G"
      },
      "source": [
        "## Настройка аугментации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjFoZqPs4unm"
      },
      "outputs": [],
      "source": [
        "# Подорбрать нужные параметры для аугментации. Если нужно посмортеть результат аугментации - вызвать метод train_dataset.__getitem__(idx)\n",
        "train_albumentations_transforms = A.Compose([\n",
        "    A.Resize(width=train_config['img_size'], height=train_config['img_size']),\n",
        "    A.HorizontalFlip(),\n",
        "    A.RandomBrightnessContrast(),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "valid_albumentations_transforms = A.Compose([A.Resize(width=train_config['img_size'], height=train_config['img_size'])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYaB76fMfbCa"
      },
      "outputs": [],
      "source": [
        "train_dataset = Data_loader(dataset_path=train_config['train_data_path'],\n",
        "                            img_size=train_config['img_size'],\n",
        "                            alb_transform=train_albumentations_transforms\n",
        "                            ) # Иннициализация датасета\n",
        "\n",
        "\n",
        "valid_dataset = Data_loader(dataset_path=train_config['valid_data_path'],\n",
        "                            img_size=train_config['img_size'],\n",
        "                            alb_transform=valid_albumentations_transforms\n",
        "                            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6-R_gTeQKVZ"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGI6d5_CtCXL",
        "outputId": "f923c519-2069-4931-e4e6-e806bd1dd91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 113MB/s]\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Указать нужную модель для обучения: cвою - CustomCNN или же из torchvision.models\n",
        "# model = CustomCNN(num_classes=4).to(device) - пример объявления CustomCNN. num_classes - количество классов\n",
        "model = models.resnet18(pretrained=True).to(device) # pretrained=True - если нужна предобученная модель\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание экземпляра класса для обучения\n",
        "trainer = Train_model(\n",
        "    model = model,\n",
        "    train_dataset = train_dataset,\n",
        "    valid_dataset = valid_dataset,\n",
        "    train_config=train_config,\n",
        ")"
      ],
      "metadata": {
        "id": "lm6SsTK-5UlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "N9tMFKOe4Erk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508f10f1-f888-4819-e8d2-7b18743f42d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 / 15\n",
            "Train_loss: 1.2824363708496094, Train_accuracy: 0.088, Valid_accuracy: 0.072, Valid_f1: 0.014, valid_precision: 0.057, valid_recall: 0.1\n",
            "epoch 2 / 15\n",
            "Train_loss: 0.18865278363227844, Train_accuracy: 0.077, Valid_accuracy: 0.071, Valid_f1: 0.013, valid_precision: 0.007, valid_recall: 0.1\n",
            "epoch 3 / 15\n",
            "Train_loss: 0.11989251524209976, Train_accuracy: 0.071, Valid_accuracy: 0.071, Valid_f1: 0.013, valid_precision: 0.007, valid_recall: 0.1\n",
            "epoch 4 / 15\n",
            "Train_loss: 0.07783243805170059, Train_accuracy: 0.072, Valid_accuracy: 0.071, Valid_f1: 0.013, valid_precision: 0.007, valid_recall: 0.1\n",
            "epoch 5 / 15\n",
            "Train_loss: 0.07300681620836258, Train_accuracy: 0.071, Valid_accuracy: 0.071, Valid_f1: 0.013, valid_precision: 0.007, valid_recall: 0.1\n",
            "epoch 6 / 15\n",
            "Train_loss: 0.2533874809741974, Train_accuracy: 0.071, Valid_accuracy: 0.071, Valid_f1: 0.013, valid_precision: 0.007, valid_recall: 0.1\n",
            "epoch 7 / 15\n",
            "Train_loss: 0.11845263093709946, Train_accuracy: 0.071, Valid_accuracy: 0.071, Valid_f1: 0.013, valid_precision: 0.007, valid_recall: 0.1\n",
            "epoch 8 / 15\n",
            "Train_loss: 0.07360488921403885, Train_accuracy: 0.071, Valid_accuracy: 0.071, Valid_f1: 0.013, valid_precision: 0.007, valid_recall: 0.1\n",
            "epoch 9 / 15\n",
            "Train_loss: 0.022191839292645454, Train_accuracy: 0.071, Valid_accuracy: 0.071, Valid_f1: 0.013, valid_precision: 0.007, valid_recall: 0.1\n",
            "epoch 10 / 15\n",
            "Train_loss: 0.03288065642118454, Train_accuracy: 0.071, Valid_accuracy: 0.071, Valid_f1: 0.013, valid_precision: 0.007, valid_recall: 0.1\n",
            "epoch 11 / 15\n",
            "Train_loss: 0.03618834540247917, Train_accuracy: 0.071, Valid_accuracy: 0.071, Valid_f1: 0.013, valid_precision: 0.007, valid_recall: 0.1\n",
            "epoch 12 / 15\n",
            "Train_loss: 0.07297872006893158, Train_accuracy: 0.071, Valid_accuracy: 0.071, Valid_f1: 0.013, valid_precision: 0.007, valid_recall: 0.1\n",
            "epoch 13 / 15\n",
            "Train_loss: 0.021571144461631775, Train_accuracy: 0.072, Valid_accuracy: 0.071, Valid_f1: 0.013, valid_precision: 0.007, valid_recall: 0.1\n",
            "epoch 14 / 15\n",
            "Train_loss: 0.3335498571395874, Train_accuracy: 0.074, Valid_accuracy: 0.071, Valid_f1: 0.013, valid_precision: 0.007, valid_recall: 0.1\n",
            "epoch 15 / 15\n",
            "Train_loss: 0.3257274925708771, Train_accuracy: 0.071, Valid_accuracy: 0.071, Valid_f1: 0.013, valid_precision: 0.007, valid_recall: 0.1\n"
          ]
        }
      ],
      "source": [
        "# Запустить обучение\n",
        "warnings.filterwarnings('ignore')\n",
        "trainer.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xjl18C7UF-Bp"
      },
      "outputs": [],
      "source": [
        "trained_model = trainer.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WWonwPQPOGY"
      },
      "source": [
        "# Тестирование"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L22x9CaUH-iS"
      },
      "outputs": [],
      "source": [
        "# Класс для тестирования модель. При иннициализации класса получает обученую модель и словарь c параметрами для тестирования\n",
        "class Test_model:\n",
        "    def __init__(self, test_dataset, test_config):\n",
        "        self.test_dataset = test_dataset\n",
        "        self.test_config = test_config\n",
        "        self.model = test_config['model']\n",
        "\n",
        "        self.test_loader = DataLoader(test_dataset, batch_size = self.test_config['batch_size'])\n",
        "\n",
        "        test_targets = []\n",
        "        for img, lbl in self.test_loader:\n",
        "            test_targets.append(lbl.numpy())\n",
        "\n",
        "        self.test_targets = np.concatenate(test_targets)\n",
        "\n",
        "\n",
        "    def test_forward(self):\n",
        "        predict_list = []\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader, 0):\n",
        "                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "                outputs = self.model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                predict_list.append(predicted.tolist())\n",
        "\n",
        "        return np.concatenate(predict_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuNrb4xA50Lb"
      },
      "source": [
        "## Настройка параметров тесирования"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUZxbnxwFrzo"
      },
      "outputs": [],
      "source": [
        "# Настроить параметры для тестирования\n",
        "test_config = {\n",
        "    'test_data_path': '/content/drive/MyDrive/hackathon/test',\n",
        "    'model': trained_model,\n",
        "    'img_size': 224, # указать тот же размер изображения, что и был при обучении\n",
        "    'batch_size': 16 # указать тот же размер батча, что и был при обучении\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE1-shDmk6E9"
      },
      "outputs": [],
      "source": [
        "test_albumentations_transforms = A.Compose([A.Resize(width=test_config['img_size'], height=test_config['img_size'])])\n",
        "\n",
        "test_dataset = Data_loader(dataset_path=test_config['test_data_path'],\n",
        "                            img_size=train_config['img_size'],\n",
        "                            alb_transform=test_albumentations_transforms\n",
        "                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nG2U4-gBFd6q"
      },
      "outputs": [],
      "source": [
        "tester = Test_model(\n",
        "    test_config=test_config,\n",
        "    test_dataset = test_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bfPOCroGqc-"
      },
      "outputs": [],
      "source": [
        "# Запустить тестовый прогон мрдели\n",
        "test_predict = tester.test_forward() # возвращает предсказание модели\n",
        "test_targets = tester.test_targets # возвращает true targets тестовой выборки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zW_SDGVHvfX"
      },
      "source": [
        "## Рассчет метрик"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlGL-5Omm4Yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fccb7b0a-8dfd-47f2-f00b-af04b9c4ca01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MulticlassAccuracy tensor([0.0712])\n",
            "MulticlassF1Score tensor([0.0712])\n",
            "MulticlassPrecision tensor([0.0712])\n",
            "MulticlassRecall tensor([0.0712])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchmetrics\n",
        "from torchmetrics import MetricTracker, MetricCollection\n",
        "from torchmetrics import Accuracy, F1Score, Precision, Recall, CohenKappa\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "list_of_metrics = [Accuracy(task=\"multiclass\", num_classes=num_classes),\n",
        "                   F1Score(task=\"multiclass\", num_classes=num_classes),\n",
        "                   Precision(task=\"multiclass\",num_classes=num_classes),\n",
        "                   Recall(task=\"multiclass\",num_classes=num_classes)\n",
        "                   ] # Указание нужных метрик для рассчета\n",
        "\n",
        "maximize_list=[True,True,True,True]\n",
        "\n",
        "metric_coll = MetricCollection(list_of_metrics)\n",
        "tracker = MetricTracker(metric_coll, maximize=maximize_list)\n",
        "\n",
        "\n",
        "pred = torch.Tensor(test_predict)\n",
        "\n",
        "label = torch.Tensor(test_targets)\n",
        "\n",
        "tracker.increment()\n",
        "tracker.update(pred, label)\n",
        "\n",
        "for key, val in tracker.compute_all().items():\n",
        "    print(key,val)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вывод\n",
        "По резултатам тестирования модель имеет низкую точность, все метрики ранвы 0.0712. При дальнейшей разработке необходимо будет попробоавть инные параметры для аугментации данных, а также изменить размер батчей при обучении, lr. Попрбовать архитектуру googlenet, так как в датасете содержутся объекты на фотография с маленьки размерами фитч."
      ],
      "metadata": {
        "id": "M7bjTC2fm8ez"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m7GioBeqnyMp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}